{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.1431874483897606,
  "eval_steps": 200,
  "global_step": 9000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008257638315441783,
      "grad_norm": 0.23560582101345062,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 8.319,
      "step": 100
    },
    {
      "epoch": 0.016515276630883566,
      "grad_norm": 0.295518159866333,
      "learning_rate": 4.958784346378019e-05,
      "loss": 8.1605,
      "step": 200
    },
    {
      "epoch": 0.02477291494632535,
      "grad_norm": 0.35518696904182434,
      "learning_rate": 4.917152373022482e-05,
      "loss": 8.1408,
      "step": 300
    },
    {
      "epoch": 0.03303055326176713,
      "grad_norm": 0.6727234721183777,
      "learning_rate": 4.875520399666945e-05,
      "loss": 8.1327,
      "step": 400
    },
    {
      "epoch": 0.04128819157720892,
      "grad_norm": 0.6968010663986206,
      "learning_rate": 4.833888426311408e-05,
      "loss": 7.6673,
      "step": 500
    },
    {
      "epoch": 0.0495458298926507,
      "grad_norm": 0.6324303150177002,
      "learning_rate": 4.7922564529558706e-05,
      "loss": 7.1256,
      "step": 600
    },
    {
      "epoch": 0.057803468208092484,
      "grad_norm": 0.5289212465286255,
      "learning_rate": 4.7506244796003335e-05,
      "loss": 6.9373,
      "step": 700
    },
    {
      "epoch": 0.06606110652353427,
      "grad_norm": 0.6531437635421753,
      "learning_rate": 4.7089925062447964e-05,
      "loss": 6.866,
      "step": 800
    },
    {
      "epoch": 0.07431874483897605,
      "grad_norm": 0.992357075214386,
      "learning_rate": 4.6673605328892594e-05,
      "loss": 6.8525,
      "step": 900
    },
    {
      "epoch": 0.08257638315441784,
      "grad_norm": 0.6105932593345642,
      "learning_rate": 4.6257285595337216e-05,
      "loss": 6.84,
      "step": 1000
    },
    {
      "epoch": 0.09083402146985962,
      "grad_norm": 0.799534261226654,
      "learning_rate": 4.5840965861781845e-05,
      "loss": 6.8398,
      "step": 1100
    },
    {
      "epoch": 0.0990916597853014,
      "grad_norm": 0.8479995131492615,
      "learning_rate": 4.5424646128226475e-05,
      "loss": 6.8409,
      "step": 1200
    },
    {
      "epoch": 0.10734929810074319,
      "grad_norm": 0.6383684277534485,
      "learning_rate": 4.500832639467111e-05,
      "loss": 6.8271,
      "step": 1300
    },
    {
      "epoch": 0.11560693641618497,
      "grad_norm": 1.1587164402008057,
      "learning_rate": 4.459200666111574e-05,
      "loss": 6.8228,
      "step": 1400
    },
    {
      "epoch": 0.12386457473162675,
      "grad_norm": 0.808832049369812,
      "learning_rate": 4.417568692756037e-05,
      "loss": 6.8141,
      "step": 1500
    },
    {
      "epoch": 0.13212221304706853,
      "grad_norm": 0.8026562333106995,
      "learning_rate": 4.3759367194005e-05,
      "loss": 6.8289,
      "step": 1600
    },
    {
      "epoch": 0.14037985136251033,
      "grad_norm": 1.303001046180725,
      "learning_rate": 4.334304746044963e-05,
      "loss": 6.8194,
      "step": 1700
    },
    {
      "epoch": 0.1486374896779521,
      "grad_norm": 0.950435996055603,
      "learning_rate": 4.292672772689426e-05,
      "loss": 6.8075,
      "step": 1800
    },
    {
      "epoch": 0.1568951279933939,
      "grad_norm": 0.6424641609191895,
      "learning_rate": 4.2510407993338886e-05,
      "loss": 6.8173,
      "step": 1900
    },
    {
      "epoch": 0.16515276630883569,
      "grad_norm": 0.7827149629592896,
      "learning_rate": 4.2094088259783515e-05,
      "loss": 6.8086,
      "step": 2000
    },
    {
      "epoch": 0.17341040462427745,
      "grad_norm": 0.8495391011238098,
      "learning_rate": 4.1677768526228145e-05,
      "loss": 6.8038,
      "step": 2100
    },
    {
      "epoch": 0.18166804293971925,
      "grad_norm": 0.6942629218101501,
      "learning_rate": 4.1261448792672774e-05,
      "loss": 6.7961,
      "step": 2200
    },
    {
      "epoch": 0.18992568125516102,
      "grad_norm": 0.8861901164054871,
      "learning_rate": 4.08451290591174e-05,
      "loss": 6.7882,
      "step": 2300
    },
    {
      "epoch": 0.1981833195706028,
      "grad_norm": 0.7697293162345886,
      "learning_rate": 4.042880932556203e-05,
      "loss": 6.7943,
      "step": 2400
    },
    {
      "epoch": 1.0064409578860445,
      "grad_norm": 0.7132156491279602,
      "learning_rate": 4.001248959200666e-05,
      "loss": 6.8353,
      "step": 2500
    },
    {
      "epoch": 1.0146985962014863,
      "grad_norm": 0.8358323574066162,
      "learning_rate": 3.959616985845129e-05,
      "loss": 6.7723,
      "step": 2600
    },
    {
      "epoch": 1.022956234516928,
      "grad_norm": 0.6074551939964294,
      "learning_rate": 3.917985012489592e-05,
      "loss": 6.7713,
      "step": 2700
    },
    {
      "epoch": 1.0312138728323699,
      "grad_norm": 0.7156887650489807,
      "learning_rate": 3.876353039134055e-05,
      "loss": 6.7767,
      "step": 2800
    },
    {
      "epoch": 1.0394715111478117,
      "grad_norm": 0.704643964767456,
      "learning_rate": 3.834721065778518e-05,
      "loss": 6.794,
      "step": 2900
    },
    {
      "epoch": 1.0477291494632535,
      "grad_norm": 0.9714632630348206,
      "learning_rate": 3.7930890924229815e-05,
      "loss": 6.7732,
      "step": 3000
    },
    {
      "epoch": 1.0559867877786953,
      "grad_norm": 1.196988821029663,
      "learning_rate": 3.7514571190674444e-05,
      "loss": 6.7746,
      "step": 3100
    },
    {
      "epoch": 1.064244426094137,
      "grad_norm": 0.8094857931137085,
      "learning_rate": 3.709825145711907e-05,
      "loss": 6.7643,
      "step": 3200
    },
    {
      "epoch": 1.0725020644095788,
      "grad_norm": 0.5753215551376343,
      "learning_rate": 3.66819317235637e-05,
      "loss": 6.7688,
      "step": 3300
    },
    {
      "epoch": 1.0807597027250206,
      "grad_norm": 0.8151212930679321,
      "learning_rate": 3.626561199000833e-05,
      "loss": 6.758,
      "step": 3400
    },
    {
      "epoch": 1.0890173410404624,
      "grad_norm": 0.6917747259140015,
      "learning_rate": 3.584929225645296e-05,
      "loss": 6.7765,
      "step": 3500
    },
    {
      "epoch": 1.0972749793559042,
      "grad_norm": 0.7148077487945557,
      "learning_rate": 3.543297252289759e-05,
      "loss": 6.7686,
      "step": 3600
    },
    {
      "epoch": 1.105532617671346,
      "grad_norm": 0.6866967082023621,
      "learning_rate": 3.501665278934222e-05,
      "loss": 6.7765,
      "step": 3700
    },
    {
      "epoch": 1.1137902559867878,
      "grad_norm": 0.8293675780296326,
      "learning_rate": 3.460033305578684e-05,
      "loss": 6.7631,
      "step": 3800
    },
    {
      "epoch": 1.1220478943022296,
      "grad_norm": 0.6812391877174377,
      "learning_rate": 3.418401332223147e-05,
      "loss": 6.77,
      "step": 3900
    },
    {
      "epoch": 1.1303055326176714,
      "grad_norm": 0.7882446646690369,
      "learning_rate": 3.37676935886761e-05,
      "loss": 6.7689,
      "step": 4000
    },
    {
      "epoch": 1.1385631709331132,
      "grad_norm": 0.755164384841919,
      "learning_rate": 3.335137385512073e-05,
      "loss": 6.7728,
      "step": 4100
    },
    {
      "epoch": 1.146820809248555,
      "grad_norm": 0.6622667908668518,
      "learning_rate": 3.293505412156536e-05,
      "loss": 6.7671,
      "step": 4200
    },
    {
      "epoch": 1.1550784475639966,
      "grad_norm": 0.710128903388977,
      "learning_rate": 3.2518734388009995e-05,
      "loss": 6.77,
      "step": 4300
    },
    {
      "epoch": 1.1633360858794384,
      "grad_norm": 0.65642911195755,
      "learning_rate": 3.2102414654454624e-05,
      "loss": 6.7612,
      "step": 4400
    },
    {
      "epoch": 1.1715937241948802,
      "grad_norm": 0.6433667540550232,
      "learning_rate": 3.168609492089925e-05,
      "loss": 6.7629,
      "step": 4500
    },
    {
      "epoch": 1.179851362510322,
      "grad_norm": 0.48975062370300293,
      "learning_rate": 3.126977518734388e-05,
      "loss": 6.77,
      "step": 4600
    },
    {
      "epoch": 1.1881090008257638,
      "grad_norm": 0.9396891593933105,
      "learning_rate": 3.085345545378851e-05,
      "loss": 6.761,
      "step": 4700
    },
    {
      "epoch": 1.1963666391412056,
      "grad_norm": 0.7810739874839783,
      "learning_rate": 3.043713572023314e-05,
      "loss": 6.7811,
      "step": 4800
    },
    {
      "epoch": 2.0046242774566476,
      "grad_norm": 0.6888651251792908,
      "learning_rate": 3.002081598667777e-05,
      "loss": 6.807,
      "step": 4900
    },
    {
      "epoch": 2.012881915772089,
      "grad_norm": 0.6153857111930847,
      "learning_rate": 2.96044962531224e-05,
      "loss": 6.7547,
      "step": 5000
    },
    {
      "epoch": 2.0211395540875308,
      "grad_norm": 0.8096628785133362,
      "learning_rate": 2.918817651956703e-05,
      "loss": 6.7542,
      "step": 5100
    },
    {
      "epoch": 2.0293971924029726,
      "grad_norm": 0.9038413166999817,
      "learning_rate": 2.8771856786011658e-05,
      "loss": 6.7503,
      "step": 5200
    },
    {
      "epoch": 2.0376548307184144,
      "grad_norm": 0.7515871524810791,
      "learning_rate": 2.8355537052456287e-05,
      "loss": 6.7805,
      "step": 5300
    },
    {
      "epoch": 2.045912469033856,
      "grad_norm": 0.7651700377464294,
      "learning_rate": 2.7939217318900917e-05,
      "loss": 6.7629,
      "step": 5400
    },
    {
      "epoch": 2.054170107349298,
      "grad_norm": 0.6429222822189331,
      "learning_rate": 2.7522897585345546e-05,
      "loss": 6.7504,
      "step": 5500
    },
    {
      "epoch": 2.0624277456647397,
      "grad_norm": 0.5725247859954834,
      "learning_rate": 2.710657785179018e-05,
      "loss": 6.7541,
      "step": 5600
    },
    {
      "epoch": 2.0706853839801815,
      "grad_norm": 0.6166346073150635,
      "learning_rate": 2.6690258118234808e-05,
      "loss": 6.7552,
      "step": 5700
    },
    {
      "epoch": 2.0789430222956233,
      "grad_norm": 0.4548911154270172,
      "learning_rate": 2.6273938384679437e-05,
      "loss": 6.7448,
      "step": 5800
    },
    {
      "epoch": 2.087200660611065,
      "grad_norm": 1.096903920173645,
      "learning_rate": 2.5857618651124066e-05,
      "loss": 6.7551,
      "step": 5900
    },
    {
      "epoch": 2.095458298926507,
      "grad_norm": 0.5776224136352539,
      "learning_rate": 2.5441298917568695e-05,
      "loss": 6.7597,
      "step": 6000
    },
    {
      "epoch": 2.1037159372419487,
      "grad_norm": 0.6319758892059326,
      "learning_rate": 2.5024979184013325e-05,
      "loss": 6.7619,
      "step": 6100
    },
    {
      "epoch": 2.1119735755573905,
      "grad_norm": 0.62889564037323,
      "learning_rate": 2.460865945045795e-05,
      "loss": 6.7539,
      "step": 6200
    },
    {
      "epoch": 2.1202312138728323,
      "grad_norm": 0.8377320170402527,
      "learning_rate": 2.4192339716902583e-05,
      "loss": 6.7506,
      "step": 6300
    },
    {
      "epoch": 2.128488852188274,
      "grad_norm": 0.9705773591995239,
      "learning_rate": 2.3776019983347212e-05,
      "loss": 6.7539,
      "step": 6400
    },
    {
      "epoch": 2.136746490503716,
      "grad_norm": 0.9030523896217346,
      "learning_rate": 2.335970024979184e-05,
      "loss": 6.7611,
      "step": 6500
    },
    {
      "epoch": 2.1450041288191577,
      "grad_norm": 0.8070012331008911,
      "learning_rate": 2.294338051623647e-05,
      "loss": 6.754,
      "step": 6600
    },
    {
      "epoch": 2.1532617671345995,
      "grad_norm": 0.730423629283905,
      "learning_rate": 2.25270607826811e-05,
      "loss": 6.7581,
      "step": 6700
    },
    {
      "epoch": 2.1615194054500413,
      "grad_norm": 0.7439809441566467,
      "learning_rate": 2.211074104912573e-05,
      "loss": 6.749,
      "step": 6800
    },
    {
      "epoch": 2.169777043765483,
      "grad_norm": 0.8250225782394409,
      "learning_rate": 2.169442131557036e-05,
      "loss": 6.7514,
      "step": 6900
    },
    {
      "epoch": 2.178034682080925,
      "grad_norm": 0.7958352565765381,
      "learning_rate": 2.1278101582014988e-05,
      "loss": 6.7621,
      "step": 7000
    },
    {
      "epoch": 2.1862923203963667,
      "grad_norm": 0.698524534702301,
      "learning_rate": 2.086178184845962e-05,
      "loss": 6.7403,
      "step": 7100
    },
    {
      "epoch": 2.1945499587118085,
      "grad_norm": 0.9222662448883057,
      "learning_rate": 2.044546211490425e-05,
      "loss": 6.7729,
      "step": 7200
    },
    {
      "epoch": 3.00280759702725,
      "grad_norm": 0.8073896765708923,
      "learning_rate": 2.002914238134888e-05,
      "loss": 6.8004,
      "step": 7300
    },
    {
      "epoch": 3.011065235342692,
      "grad_norm": 0.4991544485092163,
      "learning_rate": 1.9612822647793505e-05,
      "loss": 6.7436,
      "step": 7400
    },
    {
      "epoch": 3.0193228736581337,
      "grad_norm": 0.7239455580711365,
      "learning_rate": 1.9196502914238134e-05,
      "loss": 6.7437,
      "step": 7500
    },
    {
      "epoch": 3.0275805119735755,
      "grad_norm": 0.6735015511512756,
      "learning_rate": 1.8780183180682763e-05,
      "loss": 6.7363,
      "step": 7600
    },
    {
      "epoch": 3.0358381502890173,
      "grad_norm": 0.9506000280380249,
      "learning_rate": 1.8363863447127393e-05,
      "loss": 6.7675,
      "step": 7700
    },
    {
      "epoch": 3.044095788604459,
      "grad_norm": 0.6399574279785156,
      "learning_rate": 1.7947543713572025e-05,
      "loss": 6.7518,
      "step": 7800
    },
    {
      "epoch": 3.052353426919901,
      "grad_norm": 0.8595542907714844,
      "learning_rate": 1.7531223980016654e-05,
      "loss": 6.7427,
      "step": 7900
    },
    {
      "epoch": 3.0606110652353427,
      "grad_norm": 0.5871788859367371,
      "learning_rate": 1.7114904246461284e-05,
      "loss": 6.7481,
      "step": 8000
    },
    {
      "epoch": 3.0688687035507844,
      "grad_norm": 0.5471841096878052,
      "learning_rate": 1.6698584512905913e-05,
      "loss": 6.7434,
      "step": 8100
    },
    {
      "epoch": 3.0771263418662262,
      "grad_norm": 0.5424485206604004,
      "learning_rate": 1.6282264779350542e-05,
      "loss": 6.7438,
      "step": 8200
    },
    {
      "epoch": 3.085383980181668,
      "grad_norm": 0.4778138995170593,
      "learning_rate": 1.586594504579517e-05,
      "loss": 6.7423,
      "step": 8300
    },
    {
      "epoch": 3.09364161849711,
      "grad_norm": 0.791041374206543,
      "learning_rate": 1.54496253122398e-05,
      "loss": 6.7487,
      "step": 8400
    },
    {
      "epoch": 3.1018992568125516,
      "grad_norm": 0.5849865078926086,
      "learning_rate": 1.5033305578684432e-05,
      "loss": 6.7517,
      "step": 8500
    },
    {
      "epoch": 3.1101568951279934,
      "grad_norm": 0.8229272365570068,
      "learning_rate": 1.4616985845129061e-05,
      "loss": 6.7493,
      "step": 8600
    },
    {
      "epoch": 3.118414533443435,
      "grad_norm": 0.6060734391212463,
      "learning_rate": 1.420066611157369e-05,
      "loss": 6.7396,
      "step": 8700
    },
    {
      "epoch": 3.126672171758877,
      "grad_norm": 0.7648126482963562,
      "learning_rate": 1.3784346378018318e-05,
      "loss": 6.7412,
      "step": 8800
    },
    {
      "epoch": 3.134929810074319,
      "grad_norm": 0.6481068134307861,
      "learning_rate": 1.3368026644462947e-05,
      "loss": 6.7531,
      "step": 8900
    },
    {
      "epoch": 3.1431874483897606,
      "grad_norm": 0.7581424713134766,
      "learning_rate": 1.2951706910907576e-05,
      "loss": 6.7496,
      "step": 9000
    }
  ],
  "logging_steps": 100,
  "max_steps": 12110,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 1500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.8883564243243776e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
