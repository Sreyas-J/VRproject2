{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.992,
  "eval_steps": 200,
  "global_step": 2810,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 0.46409228444099426,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 8.3412,
      "step": 100
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 0.7196513414382935,
      "learning_rate": 4.8173431734317345e-05,
      "loss": 8.1777,
      "step": 200
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 0.643967866897583,
      "learning_rate": 4.632841328413284e-05,
      "loss": 8.1406,
      "step": 300
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 0.7092439532279968,
      "learning_rate": 4.448339483394835e-05,
      "loss": 8.1295,
      "step": 400
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 0.6489623188972473,
      "learning_rate": 4.263837638376384e-05,
      "loss": 8.1296,
      "step": 500
    },
    {
      "epoch": 1.0657777777777777,
      "grad_norm": 0.8264879584312439,
      "learning_rate": 4.079335793357934e-05,
      "loss": 8.0454,
      "step": 600
    },
    {
      "epoch": 1.2435555555555555,
      "grad_norm": 0.8830220103263855,
      "learning_rate": 3.894833948339483e-05,
      "loss": 7.7149,
      "step": 700
    },
    {
      "epoch": 1.4213333333333333,
      "grad_norm": 1.2871241569519043,
      "learning_rate": 3.710332103321034e-05,
      "loss": 7.2357,
      "step": 800
    },
    {
      "epoch": 1.5991111111111111,
      "grad_norm": 1.345313549041748,
      "learning_rate": 3.5258302583025835e-05,
      "loss": 7.0207,
      "step": 900
    },
    {
      "epoch": 1.7768888888888887,
      "grad_norm": 1.2157464027404785,
      "learning_rate": 3.341328413284133e-05,
      "loss": 6.9344,
      "step": 1000
    },
    {
      "epoch": 1.9546666666666668,
      "grad_norm": 1.0179013013839722,
      "learning_rate": 3.156826568265683e-05,
      "loss": 6.8787,
      "step": 1100
    },
    {
      "epoch": 2.1315555555555554,
      "grad_norm": 1.1778512001037598,
      "learning_rate": 2.9723247232472328e-05,
      "loss": 6.8207,
      "step": 1200
    },
    {
      "epoch": 2.3093333333333335,
      "grad_norm": 0.8753271698951721,
      "learning_rate": 2.7878228782287822e-05,
      "loss": 6.8586,
      "step": 1300
    },
    {
      "epoch": 2.487111111111111,
      "grad_norm": 1.032485842704773,
      "learning_rate": 2.6033210332103323e-05,
      "loss": 6.8239,
      "step": 1400
    },
    {
      "epoch": 2.664888888888889,
      "grad_norm": 1.2586350440979004,
      "learning_rate": 2.418819188191882e-05,
      "loss": 6.8148,
      "step": 1500
    },
    {
      "epoch": 2.8426666666666667,
      "grad_norm": 1.3876476287841797,
      "learning_rate": 2.234317343173432e-05,
      "loss": 6.8056,
      "step": 1600
    },
    {
      "epoch": 3.0195555555555558,
      "grad_norm": 0.8854379653930664,
      "learning_rate": 2.0498154981549816e-05,
      "loss": 6.7893,
      "step": 1700
    },
    {
      "epoch": 3.1973333333333334,
      "grad_norm": 1.162773847579956,
      "learning_rate": 1.8653136531365314e-05,
      "loss": 6.8036,
      "step": 1800
    },
    {
      "epoch": 3.375111111111111,
      "grad_norm": 1.3098958730697632,
      "learning_rate": 1.6808118081180812e-05,
      "loss": 6.7906,
      "step": 1900
    },
    {
      "epoch": 3.552888888888889,
      "grad_norm": 0.8405565023422241,
      "learning_rate": 1.4963099630996311e-05,
      "loss": 6.8026,
      "step": 2000
    },
    {
      "epoch": 3.7306666666666666,
      "grad_norm": 1.037149429321289,
      "learning_rate": 1.3118081180811809e-05,
      "loss": 6.7896,
      "step": 2100
    },
    {
      "epoch": 3.9084444444444446,
      "grad_norm": 1.0407967567443848,
      "learning_rate": 1.1273062730627306e-05,
      "loss": 6.8014,
      "step": 2200
    },
    {
      "epoch": 4.085333333333334,
      "grad_norm": 1.0832568407058716,
      "learning_rate": 9.428044280442804e-06,
      "loss": 6.7236,
      "step": 2300
    },
    {
      "epoch": 4.263111111111111,
      "grad_norm": 1.14105224609375,
      "learning_rate": 7.583025830258303e-06,
      "loss": 6.7666,
      "step": 2400
    },
    {
      "epoch": 4.440888888888889,
      "grad_norm": 0.9935369491577148,
      "learning_rate": 5.738007380073801e-06,
      "loss": 6.8005,
      "step": 2500
    },
    {
      "epoch": 4.618666666666667,
      "grad_norm": 1.0570992231369019,
      "learning_rate": 3.892988929889299e-06,
      "loss": 6.7847,
      "step": 2600
    },
    {
      "epoch": 4.796444444444444,
      "grad_norm": 1.003422498703003,
      "learning_rate": 2.0479704797047974e-06,
      "loss": 6.7842,
      "step": 2700
    },
    {
      "epoch": 4.974222222222222,
      "grad_norm": 0.667198657989502,
      "learning_rate": 2.029520295202952e-07,
      "loss": 6.784,
      "step": 2800
    }
  ],
  "logging_steps": 100,
  "max_steps": 2810,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2945191761248256.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
