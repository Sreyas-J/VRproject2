{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11818065,"sourceType":"datasetVersion","datasetId":7315704}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Imports**","metadata":{}},{"cell_type":"code","source":"# Standard library imports\nimport os\nimport json\nimport glob\nimport random\n\nimport pandas as pd  # Data manipulation\nfrom tqdm import tqdm  # Progress bars","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T05:39:35.259215Z","iopub.execute_input":"2025-05-18T05:39:35.259521Z","iopub.status.idle":"2025-05-18T05:39:35.647360Z","shell.execute_reply.started":"2025-05-18T05:39:35.259498Z","shell.execute_reply":"2025-05-18T05:39:35.646339Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Function: retrieve_english_value**","metadata":{}},{"cell_type":"code","source":"def retrieve_english_value(data_field):\n    \"\"\"Retrieve English text from a field with language identifiers\"\"\"\n    if not data_field:\n        return None  # No data provided\n        \n    if not isinstance(data_field, list):\n        return data_field  # Already a primitive value\n    \n    # Handle empty list\n    if not data_field:\n        return None\n    \n    # Check first entry for direct language-tagged dict\n    initial_entry = data_field[0]\n    if isinstance(initial_entry, dict):\n        if 'language_tag' in initial_entry and 'value' in initial_entry:\n            if not initial_entry['language_tag'].startswith('en_'):\n                return None\n            return initial_entry.get('value')\n    \n    # Search for English entries\n    for record in data_field:\n        if isinstance(record, dict):\n            if (record.get(\"language_tag\", \"\").startswith(\"en\")\n                and 'value' in record):\n                return record[\"value\"]\n    \n    # Fallback: first available value\n    for record in data_field:\n        if isinstance(record, dict) and 'value' in record:\n            return record['value']\n    \n    return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T05:39:35.649235Z","iopub.execute_input":"2025-05-18T05:39:35.649679Z","iopub.status.idle":"2025-05-18T05:39:35.657315Z","shell.execute_reply.started":"2025-05-18T05:39:35.649652Z","shell.execute_reply":"2025-05-18T05:39:35.656224Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Function: gather_english_keywords**","metadata":{}},{"cell_type":"code","source":"def gather_english_keywords(keyword_collection):\n    \"\"\"Gather and deduplicate English keywords into a string\"\"\"\n    if not keyword_collection or not isinstance(keyword_collection, list):\n        return None\n    \n    # Extract lowercase keywords, filtering by English or unspecified language\n    keyword_items = [\n        item['value'].strip().lower()\n        for item in keyword_collection\n        if (isinstance(item, dict)\n            and 'value' in item\n            and ('language_tag' not in item\n                 or item['language_tag'].startswith('en')))\n    ]\n    \n    # Remove duplicates while preserving order\n    tracked_keywords = set()\n    unique_keywords = [\n        kw for kw in keyword_items\n        if not (kw in tracked_keywords or tracked_keywords.add(kw))\n    ]\n    \n    # Join to single comma-separated string\n    return ', '.join(unique_keywords) if unique_keywords else None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T05:39:35.658416Z","iopub.execute_input":"2025-05-18T05:39:35.659091Z","iopub.status.idle":"2025-05-18T05:39:35.678054Z","shell.execute_reply.started":"2025-05-18T05:39:35.659055Z","shell.execute_reply":"2025-05-18T05:39:35.676948Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Main Function: create_curated_csv**","metadata":{}},{"cell_type":"code","source":"def create_curated_csv(source_dir, target_csv, image_data_csv,\n                        limit_per_type=10000, filter_empty=False):\n    \"\"\"Create a curated and balanced CSV from metadata files\n    \n    Args:\n        source_dir (str): Directory with JSON metadata files\n        target_csv (str): Destination path for the output CSV\n        image_data_csv (str): Path to the image metadata CSV\n        limit_per_type (int): Max entries per product type\n        filter_empty (bool): Remove entries with missing values\n    \"\"\"\n    # Load image metadata\n    print(\"Reading image data CSV...\")\n    img_dataframe = pd.read_csv(image_data_csv)\n    img_mapping = {row['image_id']: row\n                   for _, row in img_dataframe.iterrows()}\n    print(f\"Loaded {len(img_dataframe)} image records\")\n\n    # Parse JSON files and extract curated fields\n    product_details = {}\n    json_list = sorted(glob.glob(os.path.join(source_dir, \"listings_*.json\")))\n    print(f\"Discovered {len(json_list)} JSON files for processing\")\n\n    for json_path in tqdm(json_list, desc=\"Parsing JSON files\"):\n        with open(json_path, 'r', encoding='utf-8') as file:\n            for entry in file:\n                try:\n                    item_info = json.loads(entry.strip())\n                    key_image_id = item_info.get(\"main_image_id\")\n                    # Only include if image exists\n                    if not key_image_id or key_image_id not in img_mapping:\n                        continue\n\n                    curated_data = {\n                        'title': retrieve_english_value(item_info.get('item_name')),\n                        'category': retrieve_english_value(item_info.get('product_type')),\n                        'shade': retrieve_english_value(item_info.get('color')),\n                        'tags': gather_english_keywords(item_info.get('item_keywords'))\n                    }\n                    product_details[key_image_id] = curated_data\n                except (json.JSONDecodeError, Exception) as err:\n                    # Skip malformed entries\n                    continue\n\n    print(f\"Retrieved metadata for {len(product_details)} images\")\n\n    # Build initial records by joining image info with metadata\n    curated_records = []\n    for img_id, img_record in tqdm(img_mapping.items(), desc=\"Building initial dataset\"):\n        if img_id in product_details:\n            details = product_details[img_id]\n            # Skip blacklisted IDs or incomplete records\n            if img_id in ['518Dk4FOzZL', '719hoe+OvIL', '71Qbh8wmhnL']:\n                continue\n            if not all(details.get(field) for field in ['title','category','shade','tags']):\n                continue\n\n            # Ensure ASCII-only text\n            def check_ascii(text):\n                return isinstance(text, str) and text.isascii()\n            if not all(check_ascii(details[f]) for f in ['title','category','shade']):\n                continue\n\n            record = {\n                'filepath': img_record['path'],\n                'image_id': img_id,\n                'title': details['title'].lower(),\n                'category': details['category'].lower(),\n                'shade': details['shade'].lower(),\n                'tags': details['tags'].lower()\n            }\n            curated_records.append(record)\n\n    # Convert to DataFrame and optional filtering\n    base_dataframe = pd.DataFrame(curated_records)\n    if filter_empty:\n        base_dataframe = base_dataframe.replace('', pd.NA).dropna()\n    base_dataframe = base_dataframe.sort_values('filepath').reset_index(drop=True)\n\n    print(f\"Dataset size before balancing: {len(base_dataframe)}\")\n    print(\"\\nTop 10 categories before balancing:\")\n    print(base_dataframe['category'].value_counts().head(10))\n\n    # Balance categories by sampling\n    balanced_collection = []\n    for _, type_group in tqdm(base_dataframe.groupby('category'), desc=\"Balancing categories\"):\n        if len(type_group) <= limit_per_type:\n            balanced_collection.append(type_group)\n        else:\n            balanced_collection.append(type_group.sample(limit_per_type, random_state=42))\n\n    final_dataframe = pd.concat(balanced_collection)\n    final_dataframe = final_dataframe.sort_values('filepath').reset_index(drop=True)\n    final_dataframe.to_csv(target_csv, index=False)\n\n    # Output summary\n    print(\"\\nTop 10 categories after balancing:\")\n    print(final_dataframe['category'].value_counts().head(10))\n    print(f\"\\nData saved to: {target_csv}\")\n\n    return {\n        'processed_image_count': len(img_dataframe),\n        'metadata_found': len(product_details),\n        'pre_balance_size': len(base_dataframe),\n        'post_balance_size': len(final_dataframe),\n        'unique_categories': final_dataframe['category'].nunique()\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T05:39:35.679088Z","iopub.execute_input":"2025-05-18T05:39:35.679413Z","iopub.status.idle":"2025-05-18T05:39:35.714848Z","shell.execute_reply.started":"2025-05-18T05:39:35.679385Z","shell.execute_reply":"2025-05-18T05:39:35.713865Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Helper Function: run_processing**","metadata":{}},{"cell_type":"code","source":"def run_processing():\n    \"\"\"Configure paths and run the CSV creation pipeline\"\"\"\n    img_source_file = \"/kaggle/input/vrproject2/abo-images-small/images/metadata/images.csv\"\n    metadata_location = \"/kaggle/input/vrproject2/abo-listings/listings/metadata\"\n    output_file = \"/kaggle/working/abo-images-small/images/small/balanced_dataset.csv\"\n\n    type_cap = 11000  # Maximum samples per category\n    remove_blanks = True  # Drop incomplete records\n\n    # Ensure output directory exists\n    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n\n    # Run processing and collect results\n    results = create_curated_csv(metadata_location, output_file,\n                                 img_source_file, type_cap, remove_blanks)\n\n    # Print summary\n    print(\"\\nSummary of Processing:\")\n    print(f\"Images processed: {results['processed_image_count']}\")\n    print(f\"Images with metadata: {results['metadata_found']}\")\n    print(f\"Dataset size pre-balance: {results['pre_balance_size']}\")\n    print(f\"Dataset size post-balance: {results['post_balance_size']}\")\n    print(f\"Unique category count: {results['unique_categories']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T05:39:35.717059Z","iopub.execute_input":"2025-05-18T05:39:35.717381Z","iopub.status.idle":"2025-05-18T05:39:35.740929Z","shell.execute_reply.started":"2025-05-18T05:39:35.717358Z","shell.execute_reply":"2025-05-18T05:39:35.739714Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Main Execution**","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    run_processing()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T05:39:35.742014Z","iopub.execute_input":"2025-05-18T05:39:35.742324Z","iopub.status.idle":"2025-05-18T05:40:24.929174Z","shell.execute_reply.started":"2025-05-18T05:39:35.742297Z","shell.execute_reply":"2025-05-18T05:40:24.927923Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !cd /kagge/working\n# !ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T05:39:35.166719Z","iopub.execute_input":"2025-05-18T05:39:35.167171Z","iopub.status.idle":"2025-05-18T05:39:35.184852Z","shell.execute_reply.started":"2025-05-18T05:39:35.167138Z","shell.execute_reply":"2025-05-18T05:39:35.183885Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !zip -r file.zip /kaggle/working\n# !ls","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}