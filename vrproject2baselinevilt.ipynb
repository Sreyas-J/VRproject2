{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11818065,"sourceType":"datasetVersion","datasetId":7315704},{"sourceId":11851151,"sourceType":"datasetVersion","datasetId":7361448},{"sourceId":146066747,"sourceType":"kernelVersion"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n# !pip install transformers torch pandas pillow tqdm scikit-learn bert-score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T14:20:25.530149Z","iopub.execute_input":"2025-05-18T14:20:25.530927Z","iopub.status.idle":"2025-05-18T14:20:25.534345Z","shell.execute_reply.started":"2025-05-18T14:20:25.530900Z","shell.execute_reply":"2025-05-18T14:20:25.533744Z"},"scrolled":true},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"IMPORTS","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm.auto import tqdm\nimport torch\nfrom transformers import ViltProcessor, ViltForQuestionAnswering\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom bert_score import score as bert_score\nimport re\nfrom nltk.corpus import wordnet as wn\nimport nltk\n\n# Download required NLTK resources\nnltk.download('wordnet')\nnltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')\nnltk.download('averaged_perceptron_tagger_eng')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-18T14:27:30.246515Z","iopub.execute_input":"2025-05-18T14:27:30.247047Z","iopub.status.idle":"2025-05-18T14:27:30.622939Z","shell.execute_reply.started":"2025-05-18T14:27:30.247024Z","shell.execute_reply":"2025-05-18T14:27:30.622345Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"**Initialize Processor and Model**","metadata":{}},{"cell_type":"code","source":"DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nMODEL_NAME = \"dandelin/vilt-b32-finetuned-vqa\"\nprocessor = ViltProcessor.from_pretrained(MODEL_NAME)\nmodel = ViltForQuestionAnswering.from_pretrained(MODEL_NAME).to(DEVICE)\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T14:20:25.553731Z","iopub.execute_input":"2025-05-18T14:20:25.553899Z","iopub.status.idle":"2025-05-18T14:20:26.899271Z","shell.execute_reply.started":"2025-05-18T14:20:25.553885Z","shell.execute_reply":"2025-05-18T14:20:26.898670Z"},"scrolled":true},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"ViltForQuestionAnswering(\n  (vilt): ViltModel(\n    (embeddings): ViltEmbeddings(\n      (text_embeddings): TextEmbeddings(\n        (word_embeddings): Embedding(30522, 768)\n        (position_embeddings): Embedding(40, 768)\n        (token_type_embeddings): Embedding(2, 768)\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (patch_embeddings): ViltPatchEmbeddings(\n        (projection): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n      )\n      (token_type_embeddings): Embedding(2, 768)\n      (dropout): Dropout(p=0.0, inplace=False)\n    )\n    (encoder): ViltEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x ViltLayer(\n          (attention): ViltAttention(\n            (attention): ViltSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): ViltSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): ViltIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ViltOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n    (pooler): ViltPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (classifier): Sequential(\n    (0): Linear(in_features=768, out_features=1536, bias=True)\n    (1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n    (2): GELU(approximate='none')\n    (3): Linear(in_features=1536, out_features=3129, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"**Load Dataset**","metadata":{}},{"cell_type":"code","source":"SUBSET_SIZE = 5000\nDATA_CSV = \"/kaggle/input/vrproject2dataset/vqa_dataset.csv\"\nBATCH_SIZE = 8\nBASE_DIR = \"/kaggle/input/vrproject2/abo-images-small/images/small\" \n\ndf = pd.read_csv(DATA_CSV)\ntest_df = df.sample(n=SUBSET_SIZE, random_state=42).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T14:20:26.900435Z","iopub.execute_input":"2025-05-18T14:20:26.900647Z","iopub.status.idle":"2025-05-18T14:20:27.014204Z","shell.execute_reply.started":"2025-05-18T14:20:26.900631Z","shell.execute_reply":"2025-05-18T14:20:27.013529Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"**Helper: Number Word to Digit Map**","metadata":{}},{"cell_type":"code","source":"number_map = {\n    'zero': '0', 'one': '1', 'two': '2', 'three': '3', 'four': '4',\n    'five': '5', 'six': '6', 'seven': '7', 'eight': '8', 'nine': '9', 'ten': '10'\n}\n\npreds = []\nrefs = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T14:20:27.015000Z","iopub.execute_input":"2025-05-18T14:20:27.015283Z","iopub.status.idle":"2025-05-18T14:20:27.019387Z","shell.execute_reply.started":"2025-05-18T14:20:27.015259Z","shell.execute_reply":"2025-05-18T14:20:27.018635Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"**WUPS Calculation Function**","metadata":{}},{"cell_type":"code","source":"# Map NLTK POS tags to WordNet POS categories for WUP similarity\ndef get_wordnet_pos(word):\n    # Get POS tag for the word using NLTK\n    tag = nltk.pos_tag([word])[0][1][0].upper()\n    # Define mapping from NLTK tags to WordNet POS categories\n    tag_dict = {\"J\": wn.ADJ, \"N\": wn.NOUN, \"V\": wn.VERB, \"R\": wn.ADV}\n    # Return WordNet POS or default to NOUN if tag is unmapped\n    return tag_dict.get(tag, wn.NOUN)\n\n# Calculate Wu-Palmer (WUP) similarity for lexical similarity between predictions and references\ndef calculate_wup_score(preds, refs):\n    # Define helper function to compute WUP similarity for a single pred-ref pair\n    def wup_sim(pred, ref):\n        # Clean and tokenize prediction and reference text\n        pred_tokens = re.sub(r'[^\\w\\s]', '', pred.lower()).split()\n        ref_tokens = re.sub(r'[^\\w\\s]', '', ref.lower()).split()\n        # Return 0 if either token list is empty\n        if not pred_tokens or not ref_tokens:\n            return 0.0\n        # Initialize list to store maximum similarities for prediction tokens\n        max_similarities = []\n        # Iterate over each prediction token\n        for p_token in pred_tokens:\n            token_max_sim = 0.0\n            # Get synsets for prediction token with POS or fallback to all synsets\n            p_synsets = wn.synsets(p_token, pos=get_wordnet_pos(p_token)) or wn.synsets(p_token)\n            if not p_synsets:\n                continue\n            # Iterate over each reference token\n            for r_token in ref_tokens:\n                # Get synsets for reference token with POS or fallback\n                r_synsets = wn.synsets(r_token, pos=get_wordnet_pos(r_token)) or wn.synsets(r_token)\n                if not r_synsets:\n                    continue\n                # Compute WUP similarity for all synset pairs\n                token_sims = [wn.wup_similarity(p_syn, r_syn) or 0.0 for p_syn in p_synsets for r_syn in r_synsets]\n                if token_sims:\n                    # Store maximum similarity for this token pair\n                    token_max_sim = max(token_sims)\n            if token_max_sim > 0:\n                # Store non-zero maximum similarity\n                max_similarities.append(token_max_sim)\n        # Return average similarity or 0 if no valid similarities\n        return sum(max_similarities) / len(max_similarities) if max_similarities else 0.0\n    # Compute WUP similarity for all pred-ref pairs\n    wup_scores = [wup_sim(p, r) for p, r in zip(preds, refs)]\n    # Return average WUP score across all pairs\n    return sum(wup_scores) / len(wup_scores) if wup_scores else 0.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T14:20:27.021065Z","iopub.execute_input":"2025-05-18T14:20:27.021263Z","iopub.status.idle":"2025-05-18T14:20:27.037850Z","shell.execute_reply.started":"2025-05-18T14:20:27.021248Z","shell.execute_reply":"2025-05-18T14:20:27.037309Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"**Inference**","metadata":{}},{"cell_type":"code","source":"for i in tqdm(range(0, len(test_df), BATCH_SIZE), desc=\"Evaluating\"):\n    batch = test_df.iloc[i:i + BATCH_SIZE]\n    images = []\n    for fname in batch[\"path\"]:\n        img_path = os.path.join(BASE_DIR, fname)\n        if os.path.exists(img_path):\n            images.append(Image.open(img_path).convert(\"RGB\"))\n        else:\n            print(f\"Warning: Image not found at {img_path}\")\n            images.append(Image.new('RGB', (224, 224)))  # Placeholder for missing images\n\n    # Use raw questions\n    questions = batch[\"question\"].tolist()\n\n    # Preprocess inputs\n    encoding = processor(images, questions, padding=True, truncation=True, return_tensors=\"pt\").to(DEVICE)\n\n    # Generate answers\n    with torch.no_grad():\n        outputs = model(**encoding)\n        logits = outputs.logits\n        idx = logits.argmax(-1).tolist()\n        answers = [model.config.id2label[id] for id in idx]\n\n    # Clean predictions: strip and lowercase\n    cleaned_preds = [ans.strip().lower() for ans in answers]\n    # Convert number words to digits\n    cleaned_preds = [number_map.get(p, p) for p in cleaned_preds]\n\n    # Prepare references\n    cleaned_refs = [str(r).strip().lower() for r in batch[\"answer\"]]\n    cleaned_refs = [number_map.get(r, r) for r in cleaned_refs]\n\n    # Debug first batch\n    if i == 0:\n        print(\"Questions:\", questions)\n        print(\"Raw answers:\", answers)\n        print(\"Cleaned predictions:\", cleaned_preds)\n        print(\"References:\", cleaned_refs)\n\n    preds.extend(cleaned_preds)\n    refs.extend(cleaned_refs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T14:20:27.038506Z","iopub.execute_input":"2025-05-18T14:20:27.038688Z","iopub.status.idle":"2025-05-18T14:22:37.075590Z","shell.execute_reply.started":"2025-05-18T14:20:27.038674Z","shell.execute_reply":"2025-05-18T14:22:37.074772Z"},"scrolled":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/625 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9756b25ba224ca0a08e60fe64f19c38"}},"metadata":{}},{"name":"stdout","text":"Questions: [\"What is the dresser's color?\", 'What is the girl holding?', 'What is the shape?', 'Is this phonecase colorful?', 'What shape are the gems?', 'What pattern is displayed?', 'What animal is printed on the phone case?', 'What type of material is it?']\nRaw answers: ['brown', 'camera', 'triangle', 'yes', 'heart', 'flowers', 'dog', 'leather']\nCleaned predictions: ['brown', 'camera', 'triangle', 'yes', 'heart', 'flowers', 'dog', 'leather']\nReferences: ['brown', 'camera', 'round', 'yes', 'round', 'face', 'lion', 'leather']\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"**String Match and F1**","metadata":{}},{"cell_type":"code","source":"acc = accuracy_score(refs, preds) #String Match\nf1  = f1_score(refs, preds, average=\"macro\")\n\nprint(f\"Baseline Evaluation Results on {len(test_df)} examples:\")\nprint(f\"  • Accuracy: {acc * 100:.2f}%\")\nprint(f\"  • Macro F1  : {f1  * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T14:22:37.076795Z","iopub.execute_input":"2025-05-18T14:22:37.077337Z","iopub.status.idle":"2025-05-18T14:22:37.120939Z","shell.execute_reply.started":"2025-05-18T14:22:37.077282Z","shell.execute_reply":"2025-05-18T14:22:37.120426Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Baseline Evaluation Results on 5000 examples:\n  • Accuracy: 39.08%\n  • Macro F1  : 7.79%\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"**BERT Score and WUPS**","metadata":{}},{"cell_type":"code","source":"P, R, F1 = bert_score(preds, refs, lang='en', rescale_with_baseline=True, device=DEVICE) #89\nprint(P.mean(), R.mean(), F1.mean())\n# Take the mean over all examples\navg_precision = P.mean().item()\navg_recall    = R.mean().item()\navg_f1        = F1.mean().item()\n\nprint(f\"  • BERTScore Precision: {avg_precision*100:.2f}%\")\nprint(f\"  • BERTScore Recall   : {avg_recall*100:.2f}%\")\nprint(f\"  • BERTScore F1       : {avg_f1*100:.2f}%\")\n\nwup_score = calculate_wup_score(preds, refs)\nprint(f\"WUP Score: {wup_score*100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T14:27:40.028552Z","iopub.execute_input":"2025-05-18T14:27:40.029187Z","iopub.status.idle":"2025-05-18T14:27:55.479802Z","shell.execute_reply.started":"2025-05-18T14:27:40.029165Z","shell.execute_reply":"2025-05-18T14:27:55.479165Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"tensor(0.8758) tensor(0.8664) tensor(0.8689)\n  • BERTScore Precision: 87.58%\n  • BERTScore Recall   : 86.64%\n  • BERTScore F1       : 86.89%\nWUP Score: 69.48%\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"**Save detailed results**","metadata":{}},{"cell_type":"code","source":"OUTPUT_CSV = \"results_subset.csv\"\n\nresults_df = pd.DataFrame({\n    \"path\"      : test_df[\"path\"],\n    \"question\"  : test_df[\"question\"],\n    \"answer\"    : refs,\n    \"prediction\": preds\n})\n\nresults_df.to_csv(OUTPUT_CSV, index=False)\nprint(f\"\\nSaved detailed results to {OUTPUT_CSV}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T14:22:39.477398Z","iopub.status.idle":"2025-05-18T14:22:39.477611Z","shell.execute_reply.started":"2025-05-18T14:22:39.477506Z","shell.execute_reply":"2025-05-18T14:22:39.477516Z"}},"outputs":[],"execution_count":null}]}